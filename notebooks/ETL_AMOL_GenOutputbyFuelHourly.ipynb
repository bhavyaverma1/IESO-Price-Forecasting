{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30f6ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore') # Comment out to see warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "413ad71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parent Directoy URL\n",
    "url= \"http://reports.ieso.ca/public/GenOutputbyFuelHourly/\"\n",
    "page = requests.get(url,allow_redirects=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e145615-6ad7-4edb-ad95-b4bf98cf9ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up GCloud Storage Authentication\n",
    "from google.cloud import storage\n",
    "path_to_private_key = './ieso-dashboard-c639f1a39298.json'\n",
    "client = storage.Client.from_service_account_json(json_credentials_path=path_to_private_key)\n",
    "bucket = client.bucket('amol_javahire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36213984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve File names from parent directory url\n",
    "soup = BeautifulSoup(page.text)\n",
    "xml_cap=soup.find_all(\"a\",href=True)\n",
    "files=[]\n",
    "for element in xml_cap:\n",
    "    file_name=element.text\n",
    "    if re.search(\"\\.xml$\", file_name) and not re.search(\"_v\", file_name):\n",
    "        files.append(str(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "882bba49-3558-4a4a-87e0-9d7036eaff04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper Function to extract fuel values from each row\n",
    "def get_fuel_values(element):\n",
    "    fuels=element.find_all('fueltotal')\n",
    "    nuc_val,gas_val,hyd_val,win_val,sol_val,bio_val=None,None,None,None,None,None\n",
    "    for fuel in fuels:\n",
    "        if fuel.find(\"fuel\").text=='NUCLEAR' and fuel.find('output')!=None:\n",
    "            nuc_val=fuel.find('output').text\n",
    "        elif fuel.find(\"fuel\").text=='GAS' and fuel.find('output')!=None:\n",
    "            gas_val=fuel.find('output').text\n",
    "        elif fuel.find(\"fuel\").text=='HYDRO' and fuel.find('output')!=None:\n",
    "            hyd_val=fuel.find('output').text\n",
    "        elif fuel.find(\"fuel\").text=='WIND' and fuel.find('output')!=None:\n",
    "            win_val=fuel.find('output').text\n",
    "        elif fuel.find(\"fuel\").text=='SOLAR' and fuel.find('output')!=None:\n",
    "            sol_val=fuel.find('output').text\n",
    "        elif fuel.find(\"fuel\").text=='BIOFUEL' and fuel.find('output')!=None:\n",
    "            bio_val=fuel.find('output').text\n",
    "        else:\n",
    "            continue\n",
    "    # print(nuc_val,gas_val,hyd_val,win_val,sol_val,bio_val)\n",
    "    return nuc_val,gas_val,hyd_val,win_val,sol_val,bio_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44ac5959-4468-49ec-8ee9-37fae150731b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper Function to parse xml data to csv\n",
    "def xml_to_df(soup,col_names):\n",
    "    dic={}\n",
    "    index=0\n",
    "    created_at=soup.find('createdat').text\n",
    "    days=soup.find_all('dailydata')\n",
    "    for day in tqdm(days,desc='Processing :: '):\n",
    "        date_val=day.find('day').text\n",
    "        hours=day.find_all('hourlydata')\n",
    "        for hour in hours:\n",
    "            hour_val=hour.find('hour').text\n",
    "            nuc_val,gas_val,hyd_val,win_val,sol_val,bio_val= get_fuel_values(hour)\n",
    "\n",
    "            # Calulate total Fuel output\n",
    "            total_val=0\n",
    "            for i in [nuc_val,gas_val,hyd_val,win_val,sol_val,bio_val]:\n",
    "                if i!=None:\n",
    "                    total_val+=int(i)\n",
    "            row_data = {col_names[0]:created_at,col_names[1]: date_val, col_names[2]: hour_val, col_names[3]: nuc_val, col_names[4]: gas_val, col_names[5]: hyd_val, col_names[6]: win_val, col_names[7]: sol_val, col_names[8]: bio_val, col_names[9]: total_val}\n",
    "            dic[index] = row_data\n",
    "            index += 1\n",
    "    df = pd.DataFrame.from_dict(dic,\"index\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "667a2ab5-260d-46ae-999c-0d0f5f9667c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### LOCAL DATA CURATION\n",
    "\n",
    "# # Defining Output Data Structure and extracting and filling values correspondingly and then dump final data to ./[outdir]\n",
    "# col_names=['created_at','mkt_date','mkt_he','nuclear','gas','hydro','wind','solar','biofuel','total']\n",
    "# outdir = './GenOutputbyFuelHourly'\n",
    "# if not os.path.exists(outdir):\n",
    "#     os.mkdir(outdir)\n",
    "# for file in files:\n",
    "#     print('Downloading ' + file, end=\" \")\n",
    "#     curr_url=str(url)+str(file)\n",
    "#     page = requests.get(curr_url,allow_redirects=True)\n",
    "#     soup = BeautifulSoup(page.text, 'lxml')\n",
    "#     print(' -- Done')\n",
    "#     report_df=xml_to_df(soup,col_names)\n",
    "#     fullname = os.path.join(outdir, (str(file[:-4])))\n",
    "#     # Pickle Dump to ./out directory\n",
    "#     report_df.to_csv(fullname+'.csv',index=False)\n",
    "# print('Dumped all files in ./GenOutputbyFuelHourly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b02b0123-9d2e-46f8-9d72-20db624c25f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PUB_GenOutputbyFuelHourly.xml  -- Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing :: 100%|███████████████████████████| 234/234 [00:04<00:00, 57.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PUB_GenOutputbyFuelHourly_2015.xml  -- Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing :: 100%|███████████████████████████| 365/365 [00:06<00:00, 57.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PUB_GenOutputbyFuelHourly_2016.xml  -- Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing :: 100%|███████████████████████████| 366/366 [00:06<00:00, 56.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PUB_GenOutputbyFuelHourly_2017.xml  -- Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing :: 100%|███████████████████████████| 365/365 [00:06<00:00, 60.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PUB_GenOutputbyFuelHourly_2018.xml  -- Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing :: 100%|███████████████████████████| 365/365 [00:06<00:00, 59.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PUB_GenOutputbyFuelHourly_2019.xml  -- Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing :: 100%|███████████████████████████| 365/365 [00:06<00:00, 53.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PUB_GenOutputbyFuelHourly_2020.xml  -- Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing :: 100%|███████████████████████████| 366/366 [00:05<00:00, 61.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PUB_GenOutputbyFuelHourly_2021.xml  -- Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing :: 100%|███████████████████████████| 365/365 [00:07<00:00, 49.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PUB_GenOutputbyFuelHourly_2022.xml  -- Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing :: 100%|███████████████████████████| 234/234 [00:04<00:00, 49.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumped all files in ./GenOutputbyFuelHourly\n"
     ]
    }
   ],
   "source": [
    "### GCP DATA CURATION\n",
    "\n",
    "# Defining Output Data Structure and extracting and filling values correspondingly and then dump final data to ./[outdir]\n",
    "col_names=['created_at','mkt_date','mkt_he','nuclear','gas','hydro','wind','solar','biofuel','total']\n",
    "for file in files:\n",
    "    print('Loading ' + file, end=\" \")\n",
    "    curr_url=str(url)+str(file)\n",
    "    page = requests.get(curr_url,allow_redirects=True)\n",
    "    soup = BeautifulSoup(page.text, 'lxml')\n",
    "    print(' -- Done')\n",
    "    report_df=xml_to_df(soup,col_names)\n",
    "    \n",
    "    # Create a blob instance to upload your data into \n",
    "    blob = bucket.blob('GenOutputbyFuelHourly/'+str(file[:-4])+'.csv')\n",
    "    blob.upload_from_string(report_df.to_csv(index=False), 'text/csv')\n",
    "print('Dumped all files in ./GenOutputbyFuelHourly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cd309b5-6ab2-446e-8db0-6f1d86868294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoadJob<project=ieso-dashboard, location=US, id=59da8a99-347b-417a-bc55-d4608031321a>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Construct a BigQuery client object.\n",
    "path_to_private_key = './ieso-dashboard-c639f1a39298.json'\n",
    "client = bigquery.Client.from_service_account_json(json_credentials_path=path_to_private_key)\n",
    "\n",
    "# TODO(developer): Set table_id to the ID of the table to create.\n",
    "table_id = \"ieso-dashboard.GenOutputbyFuelHourly.test\"\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    autodetect=True,\n",
    "    write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    "    # The source format defaults to CSV, so the line below is optional.\n",
    "    source_format=bigquery.SourceFormat.CSV,\n",
    ")\n",
    "uri = \"gs://amol_javahire/GenOutputbyFuelHourly/PUB_GenOutputbyFuelHourly_*\"\n",
    "\n",
    "load_job = client.load_table_from_uri(\n",
    "    uri, table_id, job_config=job_config\n",
    ")  # Make an API request.\n",
    "\n",
    "load_job.result()  # Waits for the job to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f6a029-a4ee-4dd0-bd3b-7c0fea8f7b35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
