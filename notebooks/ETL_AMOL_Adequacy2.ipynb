{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30f6ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "warnings.simplefilter('ignore') # Comment out to see warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "413ad71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parent Directoy URL\n",
    "url= \"http://reports.ieso.ca/public/Adequacy2/\"\n",
    "page = requests.get(url,allow_redirects=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36213984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve File names from parent directory url\n",
    "soup = BeautifulSoup(page.text)\n",
    "xml_cap=soup.find_all(\"a\",href=True)\n",
    "files=[]\n",
    "for element in xml_cap:\n",
    "    file_name=element.text\n",
    "    if re.search(\"\\.xml$\", file_name) and not re.search(\"_v\", file_name):\n",
    "        files.append(str(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56f47f77-b05f-4470-b77a-e7a3eb91ffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up GCloud Storage Authentication\n",
    "from google.cloud import storage\n",
    "path_to_private_key = './ieso-dashboard-c639f1a39298.json'\n",
    "client = storage.Client.from_service_account_json(json_credentials_path=path_to_private_key)\n",
    "bucket = client.bucket('amol_javahire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb444eec",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper Function to fetch the child columns\n",
    "def fill_cap_list(element):\n",
    "    xml_cap=element.find(\"capacities\").find_all(\"capacity\")\n",
    "    cap=[]\n",
    "    for element in xml_cap:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            cap.append(None)\n",
    "            continue\n",
    "        cap.append(element.find(\"energymw\").text)\n",
    "    return cap\n",
    "def fill_out_list(element):\n",
    "    xml_out=element.find(\"outages\").find_all(\"outage\")\n",
    "    out=[]\n",
    "    for element in xml_out:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            out.append(None)\n",
    "            continue\n",
    "        out.append(element.find(\"energymw\").text)\n",
    "    return out\n",
    "def fill_off_list(element):\n",
    "    xml_off=element.find(\"offers\").find_all(\"offer\")\n",
    "    off=[]\n",
    "    for element in xml_off:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            off.append(None)\n",
    "            continue\n",
    "        off.append(element.find(\"energymw\").text)\n",
    "    return off\n",
    "def fill_sch_list(element):\n",
    "    xml_sch=element.find(\"schedules\").find_all(\"schedule\")\n",
    "    sch=[]\n",
    "    for element in xml_sch:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            sch.append(None)\n",
    "            continue\n",
    "        sch.append(element.find(\"energymw\").text)\n",
    "    return sch\n",
    "def fill_for_list(element):\n",
    "    xml_arr=element.find(\"forecasts\").find_all(\"forecast\")\n",
    "    arr=[]\n",
    "    for element in xml_arr:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            arr.append(None)\n",
    "            continue\n",
    "        arr.append(element.find(\"energymw\").text)\n",
    "    return arr\n",
    "def fill_fore_list(element):\n",
    "    xml_arr=element.find(\"forecastenergies\").find_all(\"forecastenergy\")\n",
    "    arr=[]\n",
    "    for element in xml_arr:\n",
    "        if element.find(\"energymwhr\")==None:\n",
    "            arr.append(None)\n",
    "            continue\n",
    "        arr.append(element.find(\"energymwhr\").text)\n",
    "    return arr\n",
    "def fill_off_for_list(element):\n",
    "    xml_arr=element.find(\"offerforecasts\").find_all(\"offerforecast\")\n",
    "    arr=[]\n",
    "    for element in xml_arr:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            arr.append(None)\n",
    "            continue\n",
    "        arr.append(element.find(\"energymw\").text)\n",
    "    return arr\n",
    "def fill_est_list(element):\n",
    "    xml_arr=element.find(\"estimates\").find_all(\"estimate\")\n",
    "    arr=[]\n",
    "    for element in xml_arr:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            arr.append(None)\n",
    "            continue\n",
    "        arr.append(element.find(\"energymw\").text)\n",
    "    return arr\n",
    "def fill_bid_list(element):\n",
    "    xml_arr=element.find(\"bids\").find_all(\"bid\")\n",
    "    arr=[]\n",
    "    for element in xml_arr:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            arr.append(None)\n",
    "            continue\n",
    "        arr.append(element.find(\"energymw\").text)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d643c8b-5086-4805-909a-d13312dab59f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper Function to extract and parse xml data to csv\n",
    "def xml_to_df(soup,col_names):\n",
    "    df= pd.DataFrame(columns=col_names)\n",
    "    # Ontario Capacity\n",
    "    xml_cap=soup.find(\"capacities\").find_all(\"capacity\")\n",
    "    ont_cap=[]\n",
    "    for element in xml_cap:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            ont_cap.append(None)\n",
    "            continue\n",
    "        ont_cap.append(element.find(\"energymw\").text)\n",
    "    df['ont_cap']=ont_cap\n",
    "\n",
    "    # Ontario Energy\n",
    "    xml_ene=soup.find(\"energies\").find_all(\"energy\")\n",
    "    ont_ene=[]\n",
    "    for element in xml_ene:\n",
    "        ont_ene.append(element.find(\"energymwhr\").text)\n",
    "    df['ont_ene']=ont_ene\n",
    "\n",
    "    # Internal Resources\n",
    "    xml_int=soup.find(\"internalresources\").find_all(\"internalresource\")\n",
    "    for int_element in xml_int:\n",
    "        if int_element.find(\"fueltype\").text=='Nuclear':\n",
    "            df['int_nuc_cap']=fill_cap_list(int_element)\n",
    "            df['int_nuc_out']=fill_out_list(int_element)\n",
    "            df['int_nuc_off']=fill_off_list(int_element)\n",
    "            df['int_nuc_sch']=fill_sch_list(int_element)\n",
    "        elif int_element.find(\"fueltype\").text=='Gas':\n",
    "            df['int_gas_cap']=fill_cap_list(int_element)\n",
    "            df['int_gas_out']=fill_out_list(int_element)\n",
    "            df['int_gas_off']=fill_off_list(int_element)\n",
    "            df['int_gas_sch']=fill_sch_list(int_element)\n",
    "        elif int_element.find(\"fueltype\").text=='Hydro':\n",
    "            df['int_hyd_cap']=fill_cap_list(int_element)\n",
    "            df['int_hyd_out']=fill_out_list(int_element)\n",
    "            df['int_hyd_for']=fill_fore_list(int_element)\n",
    "            df['int_hyd_off']=fill_off_list(int_element)\n",
    "            df['int_hyd_sch']=fill_sch_list(int_element)\n",
    "        elif int_element.find(\"fueltype\").text=='Wind':\n",
    "            df['int_win_cap']=fill_cap_list(int_element)\n",
    "            df['int_win_out']=fill_out_list(int_element)\n",
    "            df['int_win_for']=fill_for_list(int_element)\n",
    "            df['int_win_sch']=fill_sch_list(int_element)\n",
    "        elif int_element.find(\"fueltype\").text=='Solar':\n",
    "            df['int_sol_cap']=fill_cap_list(int_element)\n",
    "            df['int_sol_out']=fill_out_list(int_element)\n",
    "            df['int_sol_for']=fill_for_list(int_element)\n",
    "            df['int_sol_sch']=fill_sch_list(int_element)\n",
    "        elif int_element.find(\"fueltype\").text=='Biofuel':\n",
    "            df['int_bio_cap']=fill_cap_list(int_element)\n",
    "            df['int_bio_out']=fill_out_list(int_element)\n",
    "            df['int_bio_off']=fill_off_list(int_element)\n",
    "            df['int_bio_sch']=fill_sch_list(int_element)\n",
    "        elif int_element.find(\"fueltype\").text=='Other':\n",
    "            df['int_oth_cap']=fill_cap_list(int_element)\n",
    "            df['int_oth_out']=fill_out_list(int_element)\n",
    "            df['int_oth_off']=fill_off_for_list(int_element)\n",
    "            df['int_oth_sch']=fill_sch_list(int_element)\n",
    "        else:\n",
    "            print('Unknown Fueltype')\n",
    "\n",
    "    # Total Internal Resources\n",
    "    xml_tot_int=soup.find(\"internalresources\").find(\"totalinternalresources\")\n",
    "    df['int_tot_out']=fill_out_list(xml_tot_int)\n",
    "    df['int_tot_off']=fill_off_for_list(xml_tot_int)\n",
    "    df['int_tot_sch']=fill_sch_list(xml_tot_int)\n",
    "\n",
    "    # Imports\n",
    "    xml_imp=soup.find(\"zonalimports\").find_all(\"zonalimport\")\n",
    "    for imp_element in xml_imp:\n",
    "        if imp_element.find(\"zonename\").text=='Manitoba':\n",
    "            df['imp_man_off']=fill_off_list(imp_element)\n",
    "            df['imp_man_sch']=fill_sch_list(imp_element)\n",
    "        elif imp_element.find(\"zonename\").text=='Minnesota':\n",
    "            df['imp_min_off']=fill_off_list(imp_element)\n",
    "            df['imp_min_sch']=fill_sch_list(imp_element)\n",
    "        elif imp_element.find(\"zonename\").text=='Michigan':\n",
    "            df['imp_mic_off']=fill_off_list(imp_element)\n",
    "            df['imp_mic_sch']=fill_sch_list(imp_element)\n",
    "        elif imp_element.find(\"zonename\").text=='New York':\n",
    "            df['imp_new_off']=fill_off_list(imp_element)\n",
    "            df['imp_new_sch']=fill_sch_list(imp_element)\n",
    "        elif imp_element.find(\"zonename\").text=='Quebec':\n",
    "            df['imp_que_off']=fill_off_list(imp_element)\n",
    "            df['imp_que_sch']=fill_sch_list(imp_element)\n",
    "        else:\n",
    "            print('Unknown Fueltype')\n",
    "\n",
    "    # Total Imports\n",
    "    xml_tot_imp=soup.find(\"zonalimports\").find(\"totalimports\")\n",
    "    df['imp_tot_off']=fill_off_list(xml_tot_imp)\n",
    "    df['imp_tot_sch']=fill_sch_list(xml_tot_imp)\n",
    "    df['imp_tot_est']=fill_est_list(xml_tot_imp)\n",
    "    df['imp_tot_cap']=fill_cap_list(xml_tot_imp)\n",
    "\n",
    "    # Bottled Capacity\n",
    "    xml_bot_cap=soup.find(\"bottledcapacities\").find_all(\"capacity\")\n",
    "    ont_bot_cap=[]\n",
    "    for element in xml_bot_cap:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            ont_bot_cap.append(None)\n",
    "            continue\n",
    "        ont_bot_cap.append(element.find(\"energymw\").text)\n",
    "    df['ont_bot_cap']=ont_bot_cap\n",
    "\n",
    "    # Regulation\n",
    "    xml_reg=soup.find(\"regulations\").find_all(\"regulation\")\n",
    "    ont_reg=[]\n",
    "    for element in xml_reg:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            ont_reg.append(None)\n",
    "            continue\n",
    "        ont_reg.append(element.find(\"energymw\").text)\n",
    "    df['ont_reg']=ont_reg\n",
    "\n",
    "    # Total Supply\n",
    "    xml_tot_sup=soup.find(\"totalsupplies\").find_all(\"supply\")\n",
    "    ont_tot_sup=[]\n",
    "    for element in xml_tot_sup:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            ont_tot_sup.append(None)\n",
    "            continue\n",
    "        ont_tot_sup.append(element.find(\"energymw\").text)\n",
    "    df['ont_tot_sup']=ont_tot_sup\n",
    "\n",
    "    # Ontario Forecast Demand\n",
    "    xml_for_dem=soup.find(\"forecastontdemand\").find_all(\"demand\")\n",
    "    ont_for_dem=[]\n",
    "    for element in xml_for_dem:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            ont_for_dem.append(None)\n",
    "            continue\n",
    "        ont_for_dem.append(element.find(\"energymw\").text)\n",
    "    df['ont_for_dem']=ont_for_dem\n",
    "\n",
    "    # Ontario Peak Demand\n",
    "    xml_peak_dem=soup.find(\"peakdemand\").find_all(\"demand\")\n",
    "    ont_peak_dem=[]\n",
    "    for element in xml_peak_dem:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            ont_peak_dem.append(None)\n",
    "            continue\n",
    "        ont_peak_dem.append(element.find(\"energymw\").text)\n",
    "    df['ont_peak_dem']=ont_peak_dem\n",
    "\n",
    "    # Ontario Average Demand\n",
    "    xml_avg_dem=soup.find(\"averagedemand\").find_all(\"demand\")\n",
    "    ont_avg_dem=[]\n",
    "    for element in xml_avg_dem:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            ont_avg_dem.append(None)\n",
    "            continue\n",
    "        ont_avg_dem.append(element.find(\"energymw\").text)\n",
    "    df['ont_avg_dem']=ont_avg_dem\n",
    "\n",
    "    # Ontario Wind Embedded\n",
    "    xml_emb_wind=soup.find(\"windembedded\").find_all(\"embedded\")\n",
    "    ont_emb_wind=[]\n",
    "    for element in xml_emb_wind:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            ont_emb_wind.append(None)\n",
    "            continue\n",
    "        ont_emb_wind.append(element.find(\"energymw\").text)\n",
    "    df['ont_emb_wind']=ont_emb_wind\n",
    "\n",
    "    # Ontario Solar Embedded\n",
    "    xml_emb_sol=soup.find(\"solarembedded\").find_all(\"embedded\")\n",
    "    ont_emb_sol=[]\n",
    "    for element in xml_emb_sol:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            ont_emb_sol.append(None)\n",
    "            continue\n",
    "        ont_emb_sol.append(element.find(\"energymw\").text)\n",
    "    df['ont_emb_sol']=ont_emb_sol\n",
    "\n",
    "    # Dispatchable Load Capacity\n",
    "    xml_arr=soup.find(\"dispatchableload\").find(\"capacities\").find_all(\"capacity\")\n",
    "    arr=[]\n",
    "    for element in xml_arr:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            arr.append(None)\n",
    "            continue\n",
    "        arr.append(element.find(\"energymw\").text)\n",
    "    df['ont_disp_cap']=arr\n",
    "\n",
    "    # Dispatchable Load Bids\n",
    "    xml_arr=soup.find(\"dispatchableload\").find(\"bidforecasts\").find_all(\"bidforecast\")\n",
    "    arr=[]\n",
    "    for element in xml_arr:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            arr.append(None)\n",
    "            continue\n",
    "        arr.append(element.find(\"energymw\").text)\n",
    "    df['ont_disp_bid']=arr\n",
    "\n",
    "    # Dispatchable Load On\n",
    "    xml_arr=soup.find(\"dispatchableload\").find(\"scheduledon\").find_all(\"schedule\")\n",
    "    arr=[]\n",
    "    for element in xml_arr:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            arr.append(None)\n",
    "            continue\n",
    "        arr.append(element.find(\"energymw\").text)\n",
    "    df['ont_disp_on']=arr\n",
    "\n",
    "    # Dispatchable Load Off\n",
    "    xml_arr=soup.find(\"dispatchableload\").find(\"scheduledoff\").find_all(\"schedule\")\n",
    "    arr=[]\n",
    "    for element in xml_arr:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            arr.append(None)\n",
    "            continue\n",
    "        arr.append(element.find(\"energymw\").text)\n",
    "    df['ont_disp_off']=arr\n",
    "\n",
    "\n",
    "    # Hourly Demand Response Bids\n",
    "    xml_arr=soup.find(\"hourlydemandresponse\").find(\"bids\").find_all(\"bid\")\n",
    "    arr=[]\n",
    "    for element in xml_arr:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            arr.append(None)\n",
    "            continue\n",
    "        arr.append(element.find(\"energymw\").text)\n",
    "    df['ont_hdr_bid']=arr\n",
    "\n",
    "    # Hourly Demand Response Scheduled\n",
    "    xml_arr=soup.find(\"hourlydemandresponse\").find(\"schedules\").find_all(\"schedule\")\n",
    "    arr=[]\n",
    "    for element in xml_arr:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            arr.append(None)\n",
    "            continue\n",
    "        arr.append(element.find(\"energymw\").text)\n",
    "    df['ont_hdr_sch']=arr\n",
    "\n",
    "    # Hourly Demand Response Curtailed\n",
    "    xml_arr=soup.find(\"hourlydemandresponse\").find(\"curtailed\").find_all(\"curtail\")\n",
    "    arr=[]\n",
    "    for element in xml_arr:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            arr.append(None)\n",
    "            continue\n",
    "        arr.append(element.find(\"energymw\").text)\n",
    "    df['ont_hdr_cur']=arr\n",
    "\n",
    "    # Exports\n",
    "    xml_exp=soup.find(\"zonalexports\").find_all(\"zonalexport\")\n",
    "    for exp_element in xml_exp:\n",
    "        if exp_element.find(\"zonename\").text=='Manitoba':\n",
    "            df['exp_man_bid']=fill_bid_list(exp_element)\n",
    "            df['exp_man_sch']=fill_sch_list(exp_element)\n",
    "        elif exp_element.find(\"zonename\").text=='Minnesota':\n",
    "            df['exp_min_bid']=fill_bid_list(exp_element)\n",
    "            df['exp_min_sch']=fill_sch_list(exp_element)\n",
    "        elif exp_element.find(\"zonename\").text=='Michigan':\n",
    "            df['exp_mic_bid']=fill_bid_list(exp_element)\n",
    "            df['exp_mic_sch']=fill_sch_list(exp_element)\n",
    "        elif exp_element.find(\"zonename\").text=='New York':\n",
    "            df['exp_new_bid']=fill_bid_list(exp_element)\n",
    "            df['exp_new_sch']=fill_sch_list(exp_element)\n",
    "        elif exp_element.find(\"zonename\").text=='Quebec':\n",
    "            df['exp_que_bid']=fill_bid_list(exp_element)\n",
    "            df['exp_que_sch']=fill_sch_list(exp_element)\n",
    "        else:\n",
    "            print('Unknown Province')\n",
    "\n",
    "    # Total Exports\n",
    "    xml_tot_exp=soup.find(\"zonalexports\").find(\"totalexports\")\n",
    "    df['exp_tot_bid']=fill_bid_list(xml_tot_exp)\n",
    "    df['exp_tot_sch']=fill_sch_list(xml_tot_exp)\n",
    "    df['exp_tot_cap']=fill_cap_list(xml_tot_exp)\n",
    "\n",
    "    # Generation reserve holdback total\n",
    "    xml_arr=soup.find(\"generationreserveholdback\").find(\"totalorreserve\").find_all(\"orreserve\")\n",
    "    arr=[]\n",
    "    for element in xml_arr:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            arr.append(None)\n",
    "            continue\n",
    "        arr.append(element.find(\"energymw\").text)\n",
    "    df['grh_tot']=arr\n",
    "\n",
    "    # Generation reserve holdback min_10n\n",
    "    xml_arr=soup.find(\"generationreserveholdback\").find(\"min10minor\").find_all(\"min10or\")\n",
    "    arr=[]\n",
    "    for element in xml_arr:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            arr.append(None)\n",
    "            continue\n",
    "        arr.append(element.find(\"energymw\").text)\n",
    "    df['grh_min_10n']=arr\n",
    "\n",
    "    # Generation reserve holdback min_10s\n",
    "    xml_arr=soup.find(\"generationreserveholdback\").find(\"min10minspinor\").find_all(\"min10spinor\")\n",
    "    arr=[]\n",
    "    for element in xml_arr:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            arr.append(None)\n",
    "            continue\n",
    "        arr.append(element.find(\"energymw\").text)\n",
    "    df['grh_min_10s']=arr\n",
    "\n",
    "    # Generation reserve holdback LFU\n",
    "    xml_arr=soup.find(\"generationreserveholdback\").find(\"loadforecastuncertainties\").find_all(\"uncertainty\")\n",
    "    arr=[]\n",
    "    for element in xml_arr:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            arr.append(None)\n",
    "            continue\n",
    "        arr.append(element.find(\"energymw\").text)\n",
    "    df['grh_lfu']=arr\n",
    "\n",
    "    # Generation reserve holdback Allowances\n",
    "    xml_arr=soup.find(\"generationreserveholdback\").find(\"contingencyallowances\").find_all(\"allowance\")\n",
    "    arr=[]\n",
    "    for element in xml_arr:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            arr.append(None)\n",
    "            continue\n",
    "        arr.append(element.find(\"energymw\").text)\n",
    "    df['grh_add']=arr\n",
    "\n",
    "    # Total Requiremnts\n",
    "    xml_arr=soup.find(\"totalrequirements\").find_all(\"requirement\")\n",
    "    arr=[]\n",
    "    for element in xml_arr:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            arr.append(None)\n",
    "            continue\n",
    "        arr.append(element.find(\"energymw\").text)\n",
    "    df['total_req']=arr\n",
    "\n",
    "    # Capacity Excess/Shortfall\n",
    "    xml_arr=soup.find(\"excesscapacities\").find_all(\"capacity\")\n",
    "    arr=[]\n",
    "    for element in xml_arr:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            arr.append(None)\n",
    "            continue\n",
    "        arr.append(element.find(\"energymw\").text)\n",
    "    df['cap_excess']=arr\n",
    "\n",
    "    # Energy Excess/Shortfall (MWhr)\n",
    "    xml_arr=soup.find(\"excessenergies\").find_all(\"energy\")\n",
    "    arr=[]\n",
    "    for element in xml_arr:\n",
    "        if element.find(\"energymwhr\")==None:\n",
    "            arr.append(None)\n",
    "            continue\n",
    "        arr.append(element.find(\"energymwhr\").text)\n",
    "    df['energy_excess']=arr\n",
    "\n",
    "    # Offered Capacity Excess/Shortfall\n",
    "    xml_arr=soup.find(\"excessofferedcapacities\").find_all(\"capacity\")\n",
    "    arr=[]\n",
    "    for element in xml_arr:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            arr.append(None)\n",
    "            continue\n",
    "        arr.append(element.find(\"energymw\").text)\n",
    "    df['offered_cap_excess']=arr\n",
    "\n",
    "    # Resources Not Scheduled\n",
    "    xml_arr=soup.find(\"unscheduledresources\").find_all(\"unscheduledresource\")\n",
    "    arr=[]\n",
    "    for element in xml_arr:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            arr.append(None)\n",
    "            continue\n",
    "        arr.append(element.find(\"energymw\").text)\n",
    "    df['res_not_sch']=arr\n",
    "\n",
    "    # Imports Not Scheduled\n",
    "    xml_arr=soup.find(\"unscheduledimports\").find_all(\"unscheduledimport\")\n",
    "    arr=[]\n",
    "    for element in xml_arr:\n",
    "        if element.find(\"energymw\")==None:\n",
    "            arr.append(None)\n",
    "            continue\n",
    "        arr.append(element.find(\"energymw\").text)\n",
    "    df['imp_not_sch']=arr\n",
    "\n",
    "\n",
    "    # Filling Created_at, Marketing_date, Hour_ending columns\n",
    "\n",
    "    if soup.find(\"createdat\")!=None:\n",
    "        xml_cdate=soup.find(\"createdat\").text\n",
    "        df['created_at'].fillna(xml_cdate,inplace=True)\n",
    "\n",
    "    if soup.find(\"deliverydate\")!=None:\n",
    "        xml_mdate=soup.find(\"deliverydate\").text\n",
    "        df['mkt_date'].fillna(xml_mdate,inplace=True)\n",
    "\n",
    "    df['mkt_he']=list(df.index + 1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ace0b4c6-ee2b-4da3-9a18-5cdd83a278e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### LOCAL DATA CURATION\n",
    "\n",
    "# # Defining Output Data Structure and extracting and filling values correspondingly and then dump final data to ./[outdir]\n",
    "# col_names=['mkt_date', 'mkt_he', 'dacp_flag', 'file_ver', 'created_at', 'ont_cap', 'ont_ene', 'int_nuc_cap', 'int_nuc_out', 'int_nuc_off', 'int_nuc_sch', 'int_gas_cap', 'int_gas_out', 'int_gas_off', 'int_gas_sch', 'int_hyd_cap', 'int_hyd_out', 'int_hyd_for', 'int_hyd_off', 'int_hyd_sch', 'int_win_cap', 'int_win_out', 'int_win_for', 'int_win_sch', 'int_sol_cap', 'int_sol_out', 'int_sol_for', 'int_sol_sch', 'int_bio_cap', 'int_bio_out', 'int_bio_off', 'int_bio_sch', 'int_oth_cap', 'int_oth_out', 'int_oth_off', 'int_oth_sch', 'int_tot_out', 'int_tot_off', 'int_tot_sch', 'imp_man_off', 'imp_man_sch', 'imp_min_off', 'imp_min_sch', 'imp_mic_off', 'imp_mic_sch', 'imp_new_off', 'imp_new_sch', 'imp_que_off', 'imp_que_sch', 'imp_tot_off', 'imp_tot_sch', 'imp_tot_est', 'imp_tot_cap', 'ont_bot_cap', 'ont_reg', 'ont_tot_sup', 'ont_for_dem', 'ont_peak_dem', 'ont_avg_dem', 'ont_emb_wind', 'ont_emb_sol', 'ont_disp_cap', 'ont_disp_bid', 'ont_disp_on', 'ont_disp_off', 'ont_hdr_bid', 'ont_hdr_sch', 'ont_hdr_cur', 'exp_man_bid', 'exp_man_sch', 'exp_min_bid', 'exp_min_sch', 'exp_mic_bid', 'exp_mic_sch', 'exp_new_bid', 'exp_new_sch', 'exp_que_bid', 'exp_que_sch', 'exp_tot_bid', 'exp_tot_sch', 'exp_tot_cap', 'grh_tot', 'grh_min_10n', 'grh_min_10s', 'grh_lfu', 'grh_add', 'total_req', 'cap_excess', 'energy_excess', 'offered_cap_excess', 'res_not_sch', 'imp_not_sch']\n",
    "# outdir = './Adequacy2'\n",
    "# if not os.path.exists(outdir):\n",
    "#     os.mkdir(outdir)\n",
    "# for file in tqdm(files,desc='Processing :: '):\n",
    "#     curr_url=str(url)+str(file)\n",
    "#     page = requests.get(curr_url,allow_redirects=True)\n",
    "#     soup = BeautifulSoup(page.text, 'lxml')\n",
    "#     report_df=xml_to_df(soup,col_names)\n",
    "#     fullname = os.path.join(outdir, (str(file[:-4])))\n",
    "#     # Dump to ./out directory\n",
    "#     report_df.to_csv(fullname+'.csv',index=False)\n",
    "# print('Dumped all files in ./Adequacy2')\n",
    "# # print('Pickle dumped all files in ./Adequacy2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fdb7dee-53bd-4b3c-ab35-65610a419fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing :: 100%|███████████████████████████| 126/126 [05:20<00:00,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumped all files in ./Adequacy2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### GCP DATA CURATION\n",
    "\n",
    "# Defining Output Data Structure and extracting and filling values correspondingly and then dump final data to ./[outdir]\n",
    "col_names=['mkt_date', 'mkt_he', 'dacp_flag', 'created_at', 'ont_cap', 'ont_ene', 'int_nuc_cap', 'int_nuc_out', 'int_nuc_off', 'int_nuc_sch', 'int_gas_cap', 'int_gas_out', 'int_gas_off', 'int_gas_sch', 'int_hyd_cap', 'int_hyd_out', 'int_hyd_for', 'int_hyd_off', 'int_hyd_sch', 'int_win_cap', 'int_win_out', 'int_win_for', 'int_win_sch', 'int_sol_cap', 'int_sol_out', 'int_sol_for', 'int_sol_sch', 'int_bio_cap', 'int_bio_out', 'int_bio_off', 'int_bio_sch', 'int_oth_cap', 'int_oth_out', 'int_oth_off', 'int_oth_sch', 'int_tot_out', 'int_tot_off', 'int_tot_sch', 'imp_man_off', 'imp_man_sch', 'imp_min_off', 'imp_min_sch', 'imp_mic_off', 'imp_mic_sch', 'imp_new_off', 'imp_new_sch', 'imp_que_off', 'imp_que_sch', 'imp_tot_off', 'imp_tot_sch', 'imp_tot_est', 'imp_tot_cap', 'ont_bot_cap', 'ont_reg', 'ont_tot_sup', 'ont_for_dem', 'ont_peak_dem', 'ont_avg_dem', 'ont_emb_wind', 'ont_emb_sol', 'ont_disp_cap', 'ont_disp_bid', 'ont_disp_on', 'ont_disp_off', 'ont_hdr_bid', 'ont_hdr_sch', 'ont_hdr_cur', 'exp_man_bid', 'exp_man_sch', 'exp_min_bid', 'exp_min_sch', 'exp_mic_bid', 'exp_mic_sch', 'exp_new_bid', 'exp_new_sch', 'exp_que_bid', 'exp_que_sch', 'exp_tot_bid', 'exp_tot_sch', 'exp_tot_cap', 'grh_tot', 'grh_min_10n', 'grh_min_10s', 'grh_lfu', 'grh_add', 'total_req', 'cap_excess', 'energy_excess', 'offered_cap_excess', 'res_not_sch', 'imp_not_sch']\n",
    "\n",
    "for file in tqdm(files,desc='Processing :: '):\n",
    "    curr_url=str(url)+str(file)\n",
    "    page = requests.get(curr_url,allow_redirects=True)\n",
    "    soup = BeautifulSoup(page.text, 'lxml')\n",
    "    report_df=xml_to_df(soup,col_names)\n",
    "    \n",
    "    # Create a blob instance to upload your data into \n",
    "    blob = bucket.blob('Adequacy2/'+str(file[:-4])+'.csv')\n",
    "    blob.upload_from_string(report_df.to_csv(index=False), 'text/csv')\n",
    "print('Dumped all files in ./Adequacy2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35d30e35-f8cd-40be-a3b0-10e267f5ef4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoadJob<project=ieso-dashboard, location=US, id=589b0555-dce6-4db4-bc76-cd09475bcc79>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Construct a BigQuery client object.\n",
    "path_to_private_key = './ieso-dashboard-c639f1a39298.json'\n",
    "client = bigquery.Client.from_service_account_json(json_credentials_path=path_to_private_key)\n",
    "\n",
    "# TODO(developer): Set table_id to the ID of the table to create.\n",
    "table_id = \"ieso-dashboard.Adequacy2.test\"\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    autodetect=True,\n",
    "    write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    "    # The source format defaults to CSV, so the line below is optional.\n",
    "    source_format=bigquery.SourceFormat.CSV,\n",
    ")\n",
    "uri = \"gs://amol_javahire/Adequacy2/PUB_Adequacy2*\"\n",
    "\n",
    "load_job = client.load_table_from_uri(\n",
    "    uri, table_id, job_config=job_config\n",
    ")  # Make an API request.\n",
    "\n",
    "load_job.result()  # Waits for the job to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8d51c4-f1a7-42fc-90aa-58c028cbf118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
